## <center>ğŸè´ªåƒè›‡æ¸¸æˆåŠåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¨¡å‹ğŸ¤–</center>

#### English version README included. 

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)](https://pytorch.org/)

> **ä» 0 åˆ° 22000 åˆ†çš„è¿›åŒ–ï¼** æœ¬é¡¹ç›®å±•ç¤ºäº†ä¸€ä¸ªåŸºäº DQN çš„æ™ºèƒ½ä½“å¦‚ä½•é€šè¿‡è¿ç§»å­¦ä¹ ï¼Œä»æŒæ¡åŸºç¡€ç”Ÿå­˜åˆ°ç©è½¬å¤æ‚çš„ Combo & Frenzy æœºåˆ¶ã€‚ä½ å¯ä»¥è‡ªå·±ä¸Šæ‰‹æ¸¸ç©ï¼Œä¹Ÿå¯ä»¥è®­ç»ƒæˆ–è§‚çœ‹Agentæ¸¸ç©



## âš¡ Quick Start

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Kairiki-Duck/Snake_Game_with_Reinforcement_Learning_Agent.git
cd Snake_Game_with_Reinforcement_Learning_Agent
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Play the Game

```bash
python eating_snake.py
```

### 4ï¸âƒ£ Watch Trained AI Play

```bash
python agent_test.py
```

## æ“ä½œæ–¹æ³•
- **æ–¹å‘é”®** æ§åˆ¶è›‡çš„ç§»åŠ¨æ–¹å‘ï¼ˆä¸Šä¸‹å·¦å³ï¼‰ã€‚
- è›‡ä¼šè‡ªåŠ¨å‰è¿›ï¼Œç§»åŠ¨åˆ°å±å¹•è¾¹ç¼˜ä¼šç©¿è¶Šåˆ°å¦ä¸€è¾¹ã€‚

---

## é£Ÿç‰©ç±»å‹

1. **æ™®é€šé£Ÿç‰©ï¼ˆRedï¼‰**
   - åŸºç¡€ç§¯åˆ†ï¼š1åˆ†
   - æ¯åƒä¸€ä¸ªæ™®é€šé£Ÿç‰©ä¼šå¢åŠ  Combo è®¡æ•°ã€‚
   - æ¯åƒåˆ° 5 ä¸ªä¼šç”Ÿæˆ **è¶…çº§é£Ÿç‰©**ï¼Œæ¯åƒåˆ° 20 ä¸ªä¼šç”Ÿæˆ **ç¼©å°é£Ÿç‰©**ã€‚
   - Frenzy æ¨¡å¼ä¸‹ï¼Œæ¯åƒæ™®é€šé£Ÿç‰©ç§¯åˆ†å¤§å¹…æå‡ã€‚

2. **è¶…çº§é£Ÿç‰©ï¼ˆGoldï¼‰**
   - åƒåˆ°ç«‹å³è§¦å‘ **Frenzy æ¨¡å¼**ã€‚
   - åŸºç¡€ç§¯åˆ†ï¼š20åˆ† Ã— å½“å‰ Combo
   - Frenzy æ¨¡å¼ä¸‹è›‡çš„é€Ÿåº¦åŠ å¿«ï¼Œç§¯åˆ†å€ç‡æå‡ã€‚

3. **ç¼©å°é£Ÿç‰©ï¼ˆPinkï¼‰**
   - åƒåˆ°ç«‹å³è§¦å‘ **Frenzy æ¨¡å¼**ã€‚
   - ä¼šç¼©çŸ­è›‡èº«ï¼ˆæœ€å¤šä¿ç•™ 3 ä¸ªèº«ä½“æ®µï¼‰ã€‚
   - åŸºç¡€ç§¯åˆ†ï¼š20åˆ† Ã— å½“å‰ Combo
   - åŒæ ·å¯ä»¥è§¦å‘è¿å‡»æ•ˆæœã€‚

---

## Combo æœºåˆ¶
- æ¯è¿ç»­åƒåˆ°é£Ÿç‰©ï¼ŒCombo è®¡æ•°ä¼šå¢åŠ ã€‚
- Combo æ—¶é—´çª—å£ï¼š2ç§’ï¼Œå¦‚æœè¶…è¿‡æ—¶é—´æœªåƒåˆ°æ–°é£Ÿç‰©ï¼ŒCombo é‡ç½®ã€‚
- ç§¯åˆ†è®¡ç®—ï¼š`ç§¯åˆ† = é£Ÿç‰©åŸºç¡€ç§¯åˆ† Ã— Combo è®¡æ•°`

---

## Frenzy æ¨¡å¼
- Frenzy æ¨¡å¼ä¸‹ï¼š
  - è›‡çš„é€Ÿåº¦æå‡ 1.5 å€ã€‚
  - ç§¯åˆ†å€ç‡å¤§å¹…æå‡ã€‚
  - æ¸¸æˆç”»é¢å‡ºç°ç‰¹æ•ˆï¼Œå¹¶æ˜¾ç¤º "FRENZY MODE" æç¤ºã€‚
- æ¨¡å¼æŒç»­æ—¶é—´æœ‰é™ï¼Œæ—¶é—´ç»“æŸåæ¢å¤æ­£å¸¸ã€‚

---

## ç§¯åˆ†è§„åˆ™
- **æ™®é€šé£Ÿç‰©**ï¼š1 Ã— Combo  
- **è¶…çº§é£Ÿç‰© / ç¼©å°é£Ÿç‰©**ï¼š20 Ã— Combo  
- Combo è¶Šé«˜ï¼ŒåƒåŒæ ·çš„é£Ÿç‰©ç§¯åˆ†è¶Šå¤šã€‚
- åˆç†åˆ©ç”¨ Combo å’Œ Frenzy æ¨¡å¼å¯ä»¥å¿«é€Ÿæé«˜åˆ†æ•°ã€‚

---

## ğŸš€ æ ¸å¿ƒäº®ç‚¹ (Key Highlights)

### 1. è¿ç§»å­¦ä¹ ç­–ç•¥ (Transfer Learning Strategy)
è¿™æ˜¯æœ¬é¡¹ç›®æˆåŠŸçš„å…³é”®ã€‚ç”±äºå¸¦æœ‰ Combo æœºåˆ¶çš„ç¯å¢ƒå¥–åŠ±å‡½æ•°æå…¶å¤æ‚ï¼Œç›´æ¥è®­ç»ƒå®¹æ˜“å¯¼è‡´æ¨¡å‹é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚
* **é˜¶æ®µä¸€ï¼šåŸºç¡€è¯¾** - åœ¨ç»å…¸è´ªåƒè›‡ç¯å¢ƒä¸‹è®­ç»ƒ 1000 å±€ï¼Œå»ºç«‹åŸºç¡€é¿éšœå’Œå¯»è·¯é€»è¾‘ã€‚
* **é˜¶æ®µäºŒï¼šä¸“ä¸šè¯¾** - è¿ç§»æƒé‡è‡³â€œåŠ å¼ºç‰ˆâ€ç¯å¢ƒã€‚AI å¸¦ç€â€œå…ˆéªŒçŸ¥è¯†â€è¿›åœºï¼Œä»…ç”¨ 100 å±€å³å®ç°åˆ†æ•°çˆ†å‘ã€‚

### 2. ç²¾ç‚¼çš„ 11 ç»´çŠ¶æ€ç‰¹å¾ (11-D State Representation)
æ”¾å¼ƒäº†æ²‰é‡çš„åƒç´ è¾“å…¥ï¼Œé‡‡ç”¨äº†é«˜æ•ˆçš„ 11 ç»´å‘é‡ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨ CPU ä¸Šä¹Ÿèƒ½æé€Ÿæ”¶æ•›ï¼š
- **å±é™©æ¢æµ‹** (3ç»´)ï¼šå‰æ–¹ã€å·¦ä¾§ã€å³ä¾§æ˜¯å¦æœ‰éšœç¢ã€‚
- **ç§»åŠ¨æ–¹å‘** (4ç»´)ï¼šå½“å‰å‰è¿›æ–¹å‘çš„ One-hot ç¼–ç ã€‚
- **é£Ÿç‰©å®šä½** (4ç»´)ï¼šé£Ÿç‰©ç›¸å¯¹äºè›‡å¤´çš„ä¸Šä¸‹å·¦å³ä½ç½®ã€‚

### 3. è‡ªå®šä¹‰æ¸¸æˆæœºåˆ¶ (Advanced Mechanics)
ä¸åŒäºä¼ ç»Ÿè´ªåƒè›‡ï¼Œæœ¬é¡¹ç›®åœ¨ Pygame ç¯å¢ƒä¸­å¼•å…¥äº†ï¼š
- **Combo ç³»ç»Ÿ**ï¼šçŸ­æ—¶é—´å†…è¿ç»­åƒè±†åˆ†æ•°æˆå€å¢é•¿ã€‚
- **Frenzy Mode**ï¼šè§¦å‘ç‹‚æš´æ¨¡å¼ï¼Œè·å¾—è¶…é«˜é¢å¾—åˆ†å¥–åŠ±ã€‚

### 4. å¼€ç®±å³ç© (Play Now!)
ä½ å¯ä»¥è‡ªå·±ä¸Šæ‰‹æ¸¸ç©ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç”¨ä¸è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¸¸ç©ã€‚


---

## ğŸ“Š è®­ç»ƒè¡¨ç° (Performance)

* **æœ€é«˜å¾—åˆ† (Max Score):** `22000+`
* **æ”¶æ•›é€Ÿåº¦:** è¿ç§»å­¦ä¹ åï¼Œæ¨¡å‹è¿…é€Ÿé€‚åº”ï¼Œèƒ½å¤Ÿç¨³å®šçš„åˆ°è¾¾1000+åˆ†
* **ç¨³å®šæ€§:** åœ¨ $Epsilon = 0.05$ çš„æ¢ç´¢ç‡ä¸‹ï¼Œä¾ç„¶èƒ½ä¿æŒæé«˜çš„é«˜åˆ†è§¦å‘é¢‘ç‡ã€‚



---

## ğŸ“‚ æ–‡ä»¶ç»“æ„ (Project Structure)

```text
â”œâ”€â”€ agent_test.py # æµ‹è¯•è´ªåƒè›‡Agent       
â”œâ”€â”€ agent_training.py # è®­ç»ƒè´ªåƒè›‡Agent
â”œâ”€â”€ classic_agent_test.py # æµ‹è¯•ç»å…¸è´ªåƒè›‡Agent
â”œâ”€â”€ classic_agent_training.py # è®­ç»ƒç»å…¸è´ªåƒè›‡Agent
â”œâ”€â”€ eating_snake.py # å¯ä»¥è‡ªå·±ä¸Šæ‰‹ç©çš„è´ªåƒè›‡
â”œâ”€â”€ requirements.txt  # ç¯å¢ƒä¾èµ–
â”œâ”€â”€ snake_agent.pth # è´ªåƒè›‡Agentæ¨¡å‹
â”œâ”€â”€ snake_memory.pkl # è´ªåƒè›‡Agentè®°å¿†
â”œâ”€â”€ classic_snake_agent.pth # ç»å…¸è´ªåƒè›‡Agentæ¨¡å‹
â””â”€â”€ classic_snake_memory.pkl # ç»å…¸è´ªåƒè›‡Agentè®°å¿†
```

***


## <center>ğŸ Snake Game with Reinforcement Learning Agent ğŸ¤–</center>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)](https://pytorch.org/)

> **From 0 to 22,000+ score evolution!**  
> This project demonstrates how a DQN-based agent learns progressively through transfer learning â€” from basic survival skills to mastering complex Combo & Frenzy mechanics.  
> You can play the game yourself, train the agent, or watch the trained AI in action.


---

## Controls
- Use **arrow keys** to control the snake's direction (up, down, left, right).  
- The snake moves automatically. Going off one edge of the screen will make it appear on the opposite side.

---

## Food Types

1. **Normal Food (Red)**
   - Base score: 1 point  
   - Eating a normal food increases the Combo count.  
   - Every 5 foods eaten spawns a **Super Food**, every 20 foods eaten spawns a **Shrink Food**.  
   - In Frenzy mode, eating normal food gives a much higher score.

2. **Super Food (Gold)**
   - Eating it immediately triggers **Frenzy Mode**.  
   - Base score: 20 Ã— current Combo  
   - In Frenzy mode, the snake moves faster and score multiplier increases.

3. **Shrink Food (Pink)**
   - Eating it immediately triggers **Frenzy Mode**.  
   - Shrinks the snake's length.  
   - Base score: 20 Ã— current Combo  
   - Can also trigger combo bonuses.

---

## Combo Mechanic
- Each consecutive food eaten increases the Combo count.  
- Combo window: 2 seconds. If no new food is eaten within this time, Combo resets.  
- Score calculation: `Score = Base food score Ã— Combo count`

---

## Frenzy Mode
- During Frenzy Mode:  
  - Snake speed increases by 1.5Ã—  
  - Score multiplier increases significantly  
  - Special visual effects appear, with a "FRENZY MODE" indicator  
- Frenzy Mode lasts for a limited time and ends automatically.

---

## Scoring Rules
- **Normal Food**: 1 Ã— Combo  
- **Super Food / Shrink Food**: 20 Ã— Combo  
- The higher the Combo, the more points each food gives.  
- Using Combo and Frenzy Mode effectively can boost your score quickly.

---

## ğŸš€ Key Highlights

### 1. Transfer Learning Strategy

This is the core reason behind the success of the project.  
Due to the highly complex reward structure introduced by the Combo system, direct training often leads to local optima.

* **Stage 1: Fundamentals**  
  Train the agent for 1000 episodes in the classic Snake environment to learn collision avoidance and pathfinding.

* **Stage 2: Advanced Training**  
  Transfer the learned weights into the enhanced environment.  
  With prior knowledge, the agent achieves score explosion within only 100 episodes.

---

### 2. Efficient 11-D State Representation

Instead of computationally expensive pixel inputs, we use an efficient 11-dimensional feature vector, allowing fast convergence even on CPU:

- **Danger Detection (3 dims)**  
  Whether there is danger straight, left, or right.

- **Movement Direction (4 dims)**  
  One-hot encoding of the current movement direction.

- **Food Location (4 dims)**  
  Relative position of the food (up, down, left, right).

---

### 3. Advanced Game Mechanics

Unlike traditional Snake, this project introduces several custom mechanics implemented in Pygame:

- **Combo System**  
  Consecutive food consumption within a short time window multiplies rewards.

- **Frenzy Mode**  
  Special state with significantly boosted scoring potential.

---

### 4. Play Now!

You can:

- ğŸ® Play manually
- ğŸ¤– Watch the trained AI play
- ğŸ§  Train the agent yourself

---

## ğŸ“Š Performance

- **Max Score:** `22000+`
- **Convergence Speed:** After transfer learning, the agent rapidly adapts and consistently reaches 1000+ scores.
- **Stability:** Even with an exploration rate of $Epsilon = 0.05$, the agent maintains a high frequency of high-score runs.

---

## ğŸ“‚ Project Structure

```text
â”œâ”€â”€ agent_test.py                 # Test enhanced Snake agent
â”œâ”€â”€ agent_training.py             # Train enhanced Snake agent
â”œâ”€â”€ classic_agent_test.py         # Test classic Snake agent
â”œâ”€â”€ classic_agent_training.py     # Train classic Snake agent
â”œâ”€â”€ eating_snake.py               # Playable Snake game
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ snake_agent.pth               # Trained enhanced model
â”œâ”€â”€ snake_memory.pkl              # Replay memory
â”œâ”€â”€ classic_snake_agent.pth       # Classic model
â””â”€â”€ classic_snake_memory.pkl      # Classic replay memory


```


